{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thinkture\\tcm_backend\\venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\Thinkture\\tcm_backend\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://admin:admin@localhost:6024/langchain\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=huggingface_embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_files ['paul (1).pdf', 'Resume_OngYuanQin (5).pdf', 'SQL-Cheat-Sheet-PDF (4).pdf']\n",
      "Loading PDF: D:\\Thinkture\\tcm_backend\\temp_sync\\paul (1).pdf\n",
      "Loading PDF: D:\\Thinkture\\tcm_backend\\temp_sync\\Resume_OngYuanQin (5).pdf\n",
      "Loading PDF: D:\\Thinkture\\tcm_backend\\temp_sync\\SQL-Cheat-Sheet-PDF (4).pdf\n",
      "Total pages loaded: 11\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "{'source': 'D:\\\\Thinkture\\\\tcm_backend\\\\temp_sync\\\\paul (1).pdf', 'page': 8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "dict_path = r\"D:\\Thinkture\\tcm_backend\\temp_sync\"\n",
    "import os\n",
    "\n",
    "# Get the list of PDF files in the directory\n",
    "pdf_files = [f for f in os.listdir(dict_path) if f.endswith('.pdf')]\n",
    "\n",
    "print(\"pdf_files\",pdf_files)\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDF files found in the directory.\")\n",
    "else:\n",
    "    pages = []\n",
    "    for pdf_file in pdf_files:\n",
    "        file_path = os.path.join(dict_path, pdf_file)\n",
    "        print(f\"Loading PDF: {file_path}\")\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        async for page in loader.alazy_load():\n",
    "            pages.append(page)\n",
    "\n",
    "    print(f\"Total pages loaded: {len(pages)}\")\n",
    "\n",
    "print(type(pages[0]))\n",
    "print(f\"{pages[8].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dict_path = r\"D:\\Thinkture\\tcm_backend\\temp_sync\"\n",
    "loader = DirectoryLoader(dict_path)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)\n",
    "\n",
    "chunks = splitter.split_documents(pages)\n",
    "\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='OngYuanQinAddress:JohorBahru,Malaysia|Mobile:(+60)13-7698311|Email:yuanqin1108@gmail.comLinkedIn|PersonalWebsite|GitHub\n",
      "SUMMARYAnAIsoftwareengineerwithtwoyearsofexperience,IampassionateaboutleveragingmyexpertiseinLargeLanguageModel,NaturalLanguageProcessing,ComputerVision,andsoftwaredevelopment.Committedtoinnovation,IseekachallengingroletocontributetoimpactfulprojectsandfurtheradvancemyskillsinAIandsoftwaredevelopment.\n",
      "WORKEXPERIENCEIntelMicroelectronics(M)Sdn.Bhd.(Oct2022-Present)ArtificialIntelligenceEngineer•DevelopedachatbotusingLangChainAgentandOpenAIAPIforengineerstoreadandupdatetickets.•DevelopedadataminingpipelineusingNLPandPython,andvisualizedthedataanalysisresultswithPowerBI.•CreatedanddesignedGenerativeAIplatformswithseamlessAPIintegrationusingReact.jsandRedux.•BuiltasmartticketinganalysismicroservicesinC#forasmartchatbotplatform.•DevelopedanautomatedFAQgeneratorusingPythonandNLP,increasingtheFAQgenerationrateperweek.•CreatedpipelineforLLMstocomprehendcomplexdiagramsviacomputervisionandPython.•ContributedtoanenterpriseAIchatbottoenhancecustomerexperiences,integratingaliveagentplatform.•DesignedAIbenchmarkingscenariostooptimizemodelperformanceusingOpenVino,PyTorch,andTensorFlow.•Fine-tunedparaphrasemodelfromHuggingFacetoexpandthelimitedtrainingdatasetbyapproximately500%.' metadata={'source': 'D:\\\\Thinkture\\\\tcm_backend\\\\temp_sync\\\\Resume_OngYuanQin (5).pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thinkture\\tcm_backend\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db <langchain_postgres.vectorstores.PGVector object at 0x0000017C9B064C40>\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "db=PGVector.from_documents(documents=chunks,embedding=huggingface_embeddings,connection=connection,collection_name=collection_name)\n",
    "print(\"db\",db)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='98a9c90d-957b-49bb-894e-77c90321a2c2', metadata={'page': 0, 'source': 'D:\\\\Thinkture\\\\tcm_backend\\\\temp_sync\\\\Resume_OngYuanQin (5).pdf'}, page_content='OngYuanQinAddress:JohorBahru,Malaysia|Mobile:(+60)13-7698311|Email:yuanqin1108@gmail.comLinkedIn|PersonalWebsite|GitHub\\nSUMMARYAnAIsoftwareengineerwithtwoyearsofexperience,IampassionateaboutleveragingmyexpertiseinLargeLanguageModel,NaturalLanguageProcessing,ComputerVision,andsoftwaredevelopment.Committedtoinnovation,IseekachallengingroletocontributetoimpactfulprojectsandfurtheradvancemyskillsinAIandsoftwaredevelopment.\\nWORKEXPERIENCEIntelMicroelectronics(M)Sdn.Bhd.(Oct2022-Present)ArtificialIntelligenceEngineer•DevelopedachatbotusingLangChainAgentandOpenAIAPIforengineerstoreadandupdatetickets.•DevelopedadataminingpipelineusingNLPandPython,andvisualizedthedataanalysisresultswithPowerBI.•CreatedanddesignedGenerativeAIplatformswithseamlessAPIintegrationusingReact.jsandRedux.•BuiltasmartticketinganalysismicroservicesinC#forasmartchatbotplatform.•DevelopedanautomatedFAQgeneratorusingPythonandNLP,increasingtheFAQgenerationrateperweek.•CreatedpipelineforLLMstocomprehendcomplexdiagramsviacomputervisionandPython.•ContributedtoanenterpriseAIchatbottoenhancecustomerexperiences,integratingaliveagentplatform.•DesignedAIbenchmarkingscenariostooptimizemodelperformanceusingOpenVino,PyTorch,andTensorFlow.•Fine-tunedparaphrasemodelfromHuggingFacetoexpandthelimitedtrainingdatasetbyapproximately500%.'),\n",
       " Document(id='97473ac2-70ae-4435-a8b8-4283654091df', metadata={'page': 0, 'source': 'D:\\\\Thinkture\\\\tcm_backend\\\\temp_sync\\\\Resume_OngYuanQin (5).pdf'}, page_content='OngYuanQinAddress:JohorBahru,Malaysia|Mobile:(+60)13-7698311|Email:yuanqin1108@gmail.comLinkedIn|PersonalWebsite|GitHub\\nSUMMARYAnAIsoftwareengineerwithtwoyearsofexperience,IampassionateaboutleveragingmyexpertiseinLargeLanguageModel,NaturalLanguageProcessing,ComputerVision,andsoftwaredevelopment.Committedtoinnovation,IseekachallengingroletocontributetoimpactfulprojectsandfurtheradvancemyskillsinAIandsoftwaredevelopment.\\nWORKEXPERIENCEIntelMicroelectronics(M)Sdn.Bhd.(Oct2022-Present)ArtificialIntelligenceEngineer•DevelopedachatbotusingLangChainAgentandOpenAIAPIforengineerstoreadandupdatetickets.•DevelopedadataminingpipelineusingNLPandPython,andvisualizedthedataanalysisresultswithPowerBI.•CreatedanddesignedGenerativeAIplatformswithseamlessAPIintegrationusingReact.jsandRedux.•BuiltasmartticketinganalysismicroservicesinC#forasmartchatbotplatform.•DevelopedanautomatedFAQgeneratorusingPythonandNLP,increasingtheFAQgenerationrateperweek.•CreatedpipelineforLLMstocomprehendcomplexdiagramsviacomputervisionandPython.•ContributedtoanenterpriseAIchatbottoenhancecustomerexperiences,integratingaliveagentplatform.•DesignedAIbenchmarkingscenariostooptimizemodelperformanceusingOpenVino,PyTorch,andTensorFlow.•Fine-tunedparaphrasemodelfromHuggingFacetoexpandthelimitedtrainingdatasetbyapproximately500%.'),\n",
       " Document(id='39825306-3b30-416e-a99b-597494139cec', metadata={'page': 0, 'source': 'D:\\\\Thinkture\\\\tcm_backend\\\\temp_sync\\\\Resume_OngYuanQin (5).pdf'}, page_content='SKILLS/CERTIFICATIONSProgramming:Python,React,C++,C#,Java,JavaScript,PHP,HTML,CSS,FlutterAIorNLPLibraries/Frameworks:Lanchain,Pytorch,TensorFlow,OpenVino,Scikit-learn,NLTK,SpaCy,NEROthers:MySQL,SQLite,LinuxCertifications:AWSCertifiedCloudPractitioner,HuaweiCertifiedICTAssociate-AISoftware:Git,VisualStudioCode,VisualStudio,PowerBI,AndroidStudio,MicrosoftOfficeLanguage:Chinese(Native),English(Fluent),BahasaMalaysia(Fluent)')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs={'k': 3})  # default 4\n",
    "query = \"Do you have any experience in Artificial Intelligence Engineer\"\n",
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "def setup_conversational_chain(retriever):\n",
    "        MODEL = \"llama3.1\"\n",
    "        llm = ChatOllama(model=MODEL, temperature=0)\n",
    "        parser = StrOutputParser()\n",
    "        \n",
    "        template = \"\"\"Answer the question based ONLY on the following context:\n",
    "        {context}\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "\n",
    "        def format_docs(docs):  \n",
    "            format_docs = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "            return format_docs\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        try:\n",
    "            chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | parser\n",
    "            )\n",
    "            print(\"Chain setup completed successfully\")\n",
    "            return chain\n",
    "        except Exception as e:\n",
    "            print(f\"Error in setup_conversational_chain: {str(e)}\")\n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MultiQueryRetriever automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the MultiQueryRetriever can mitigate some of the limitations of the distance-based retrieval and get a richer set of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain setup completed successfully\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "MODEL = \"llama3.1\"\n",
    "llm = ChatOllama(model=MODEL, temperature=0)\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_store.as_retriever(search_kwargs={'k': 4}),\n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "chain = setup_conversational_chain(retriever)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm familiar with the Cow Crossing Detection Alert System. According to the context provided, it's a research project developed by Ong Yuan Qin in 2022.\\n\\nHere are some details about the project:\\n\\n* It uses Python, YOLOV3, deep learning, and Raspberry Pi to detect and identify cows.\\n* The system recognizes distinct cow sounds for enhanced detection.\\n* When cows are detected on roadways, it sends alerts to subscribed devices (computers and smartphones).\\n\\nLet me know if you'd like more information!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\" do you knowCowCrossingDetectionAlertSystem\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-26 16:54:06.363456+08:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "sg_time = pytz.timezone(\"Asia/Singapore\") \n",
    "time = datetime.now(sg_time)\n",
    "print(time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
